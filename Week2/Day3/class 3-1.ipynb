{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS492: 전산학특강<스마트에너지를 위한 인공지능> \n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule for CNN\n",
    "\n",
    "3. **Basic of CNN** (Day3) <br>\n",
    "    3-1. Convolutional neural network <br>\n",
    "    3-2. Layers composing CNN <br>\n",
    "    3-3. Image classification using CNN\n",
    "    \n",
    "1. **Transfer learning with pre-trained CNNs** (Day4) <br>\n",
    "    4-1. Several well-known CNN models <br>\n",
    "    4-2. Tutorial of the pre-trained models using Keras API <br>\n",
    "    4-3. Feature extraction using pre-trained model <br>\n",
    "    4-4. Fine tuning our classification model  <br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3 - Basic of CNN\n",
    "### 3-1. Convolutional neural network (CNN)\n",
    "- A convolutional neural networks (CNN) is a class of deep neural networks, most commonly **<font color='red'>applied to analyzing visual tasks</font>**.\n",
    "- The networks consist of multiple layers of small neuron collections which process portions of the input image, called **<font color='red'>receptive fields</font>**.\n",
    "    - The connectivity pattern between these neurons is inspired by the organization of the animal visual cortex.\n",
    "- The outputs of these collections are then tiled so that their input regions overlap, to obtain a **<font color='red'>better representation</font>** of the original image; this is repeated for every such layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of CNN structure\n",
    "\n",
    "<img src=http://playagricola.com/Kaggle/extract.png width=\"800\">\n",
    "\n",
    "- CNN consists of a series of <font color='red'>convolutional, non-linear, pooling (downsampling), and fully connected layers</font>.\n",
    "- The convolutiional, non-linear and pooling layers are to <font color='red'>extract a feature map (or activation map)</font>.\n",
    "- The fully connected layer is to <font color='red'>classify a target using the extracted feature map</font> (e.g. classification a single class of input image or a probability of classes that best describes the image in image classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Layers composing CNN\n",
    "\n",
    "#### Convolutional layer\n",
    "The first layer in a CNN is usually a **convolutional layer**.\n",
    "\n",
    "<img src=https://qph.fs.quoracdn.net/main-qimg-f0c8518784fdef4130a781181eae1a11 width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional filters**\n",
    "\n",
    "<img src=\"images/conv_filter_ex.png\">\n",
    "\n",
    "- A convolutional filter much like a **kernel** in image recognition is a small matrix useful for blurring, sharpening, embossing, edge detection, and more.\n",
    "- This is accomplished by computing a convolution between an filter and an image.\n",
    "- The main difference **_here_** is that the **conv matrices are learned</font>**.\n",
    "    - This means that the convolutional filters are learned as a weights during training the CNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution** \n",
    "\n",
    "As the filter is sliding, or **<font color='red'>convolving</font>**, around the input image, it multiplies the values in the filter with the original pixel values of the image (a.k.a. computing element-wise multiplication) and add them to get a convolved value.\n",
    "\n",
    "<img src=https://adeshpande3.github.io/assets/ActivationMap.png width=\"600\">\n",
    "\n",
    "Now, we repeat this process for every location on the input volume. And, next step would be moving the filter to the right by 1 unit, then right again by 1, and so on. After sliding the filter over all the locations, we are left with an array of numbers usually called an **<font color='red'>activation map</font>** or **<font color='red'>feature map</font>**.\n",
    "\n",
    "<img src=https://miro.medium.com/max/1800/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stride and Padding**\n",
    "\n",
    "As main parameters of convolutional layer, we can change to modify the behavior of each convolutional layer by using them.\n",
    "\n",
    "Stride: Controls how the filter convolves around the input volume.\n",
    " - In the above example, the filter convolves around the input volume by shifting **one** unit at a time\n",
    " - In that case, the stride was implicitly set at 1.\n",
    " - Stride is normally set in a way so that the output volume is an integer and not a fraction.\n",
    " \n",
    "<img src=https://miro.medium.com/max/1580/1*L4T6IXRalWoseBncjRr4wQ@2x.gif width=\"500\">\n",
    "<img src=https://miro.medium.com/max/1442/1*4wZt9G7W7CchZO-5rVxl5g@2x.gif width=\"500\">\n",
    "\n",
    " \n",
    " \n",
    "Padding\n",
    " - The size of the feature map is smaller than the input, because the convolution filter needs to be contained in the input. \n",
    " - If we want to maintain the same dimensionality, we can use padding to surround the input with zeros.\n",
    " \n",
    "<img src=https://miro.medium.com/max/2126/1*W2D564Gkad9lj3_6t9I2PA@2x.gif width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More details for computation of convolutional filter (reference material)**\n",
    "\n",
    "##### High level perspective\n",
    "\n",
    "Let’s talk about briefly what this convolution is actually doing from a high level. Each of these filters can be thought of as **feature identifiers** (e.g. *straight edges, simple colors, curves*)\n",
    "\n",
    "<img src=https://adeshpande3.github.io/assets/Filter.png width=\"600\">\n",
    "\n",
    "\n",
    "\n",
    "##### Visualisation of the Receptive Field\n",
    "<img src=https://adeshpande3.github.io/assets/OriginalAndFilter.png width=\"600\">\n",
    "<img src=https://adeshpande3.github.io/assets/FirstPixelMulitiplication.png width=\"600\">\n",
    "<img src=https://adeshpande3.github.io/assets/SecondMultiplication.png width=\"600\">\n",
    "\n",
    "The value is much lower! This is because there wasn’t anything in the image section that responded to the curve detector filter. Remember, the output of this conv layer is an activation map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU (Rectified Linear Units) layer\n",
    "\n",
    "Now, in a traditional convolutional neural network architecture, there are other layers that are interspersed between these conv layers. <br>\n",
    "(e.g. Input->Conv->ReLU->Conv->ReLU->Pool->Conv->ReLU->Conv->ReLU->Pool->Fully connected)\n",
    "\n",
    "After each conv layer, the **ReLU layer** is convention to apply a *nonlinear layer* (or **activation layer**) immediately afterward. The purpose of this layer is to introduce nonlinearity to a system that basically has just been computing linear operations during the conv layers (just element wise multiplications and summations)\n",
    "\n",
    "**The advantages of ReLU layer**\n",
    "- It works far better than other nonlinear functions (e.g. tanh and sigmoid), because the network is able to train a lot faster (due to computational efficiency) without making a significant difference to the accuracy.\n",
    "- It also helps to alleviate the **vanishing gradient problem**, which is the issue where the lower layers of the network train very slowly because the gradient decreases exponentially through the layers.\n",
    "\n",
    "**ReLU function**\n",
    "- The **ReLu** function is defined as $f(x) = \\max(0, x)$.\n",
    "- A smooth approximation to the rectifier is the *analytic function*: $f(x) = \\ln(1 + e^x)$, which is called the **softplus** function.\n",
    "- The derivative of softplus is $f'(x) = e^x / (e^x + 1) = 1 / (1 + e^{-x})$, i.e. the **logistic function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling layer\n",
    "\n",
    "After some ReLU layers, it is customary to apply a **<font color='red'>pooling layer</font>** (aka *downsampling layer*). In this category, there are also several layer options, with **maxpooling** being the most popular. (There are other options such average pooling and L2-norm pooling.)\n",
    "\n",
    "<img src=https://miro.medium.com/max/2344/1*ReZNSf_Yr7Q1nqegGirsMQ@2x.png width=\"600\">\n",
    "\n",
    "\n",
    "**The purpose of pooling layer**\n",
    "- Reduce the amount of parameters\n",
    "    - The pooling layer drastically reduces the spatial dimension (the length and the width but not the depth) of the input volume.\n",
    "    - By reducing the diemnsion, there remain more important features of an input image.\n",
    "- Control an overfitting\n",
    "    - Because reduce the amount of paraeters and complexity of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layer\n",
    "\n",
    "The last layer is an important one, namely the **Fully Connected Layer**. This was the last class we learned. \n",
    "\n",
    "Basically, a FC layer looks at what high level features most strongly correlate to a particular class. It has particular weights so that when you compute the products between the weights and the previous layer, you get the correct probabilities for the different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Going further: Convolution Arithmetic\n",
    "\n",
    "If you want to go further with Convolution and you want to fully understand how convolution works with all the details we omitted in this notebook, I strongly suggest to read this terrific paper: [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285).\n",
    "\n",
    "This paper is also referenced (with animations) in the `theano` main documentation: [convnet tutorial](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
